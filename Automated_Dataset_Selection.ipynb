{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automated_Dataset_Selection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riacheruvu/automated-data-science/blob/master/Automated_Dataset_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2Jt3UowZ7CZl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Automated Dataset Selection"
      ]
    },
    {
      "metadata": {
        "id": "4buMC5YUdcfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a preliminary, work in progress attempt to parse results from Google Data Search using BeautifulSoup in response to a query (\"business problem\") and apply fuzzy string matching to the query in order to determine the appropriate dataset.\n",
        "\n",
        "Please ignore the unclean code and comments; a thorough clean-up and revision of the implementation is coming soon."
      ]
    },
    {
      "metadata": {
        "id": "4I7fAiKb7CZm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Packages"
      ]
    },
    {
      "metadata": {
        "id": "yrIVgmz77CZo",
        "colab_type": "code",
        "outputId": "7b2438ee-1e7a-4e55-e9a2-0564068d8343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "import webbrowser\n",
        "import requests\n",
        "#from urllib.request import urlopen as uReq\n",
        "import urllib\n",
        "!pip install fuzzywuzzy\n",
        "from bs4 import BeautifulSoup\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.6/dist-packages (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OtFsQORh7CZt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Read and analyze your request"
      ]
    },
    {
      "metadata": {
        "id": "DxIxhxCZ7CZu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hi! This tool is meant for supervised learning applications (in other words, given some data, the machine learning algorithm will make predictions). It also only supports prediction of a single feature at the moment.\n",
        "\n",
        "Answer a few questions about the type of business problem you're interested in, and we'll whip up some datasets you might be interested in."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "oTs3F_8x7CZu",
        "colab_type": "code",
        "outputId": "9a32ee52-9f7b-4402-ed24-e7eb2cbaa2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "#Code for Ipython widgets\n",
        "\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display\n",
        "text = widgets.Text()\n",
        "new_text = widgets.Text()\n",
        "even_newer_text = widgets.Text()\n",
        "\n",
        "print(\"What is the topic of the business problem *in a few words*?\")\n",
        "display(text)\n",
        "\n",
        "print(\"What do you want to predict (your target variable)?\")\n",
        "display(new_text)\n",
        "\n",
        "print(\"What information do you want to use to predict the target variable?\")\n",
        "display(even_newer_text)\n",
        "\n",
        "def handle_topic_submit(sender):\n",
        "    return text.value\n",
        "\n",
        "def handle_submit(sender):\n",
        "    print(\"Got it!\", sender.value)\n",
        "    \n",
        "text.on_submit(handle_topic_submit)\n",
        "new_text.on_submit(handle_submit)\n",
        "variables = new_text.value\n",
        "even_newer_text.on_submit(handle_submit)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is the topic of the business problem *in a few words*?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c256ece338246a594e35362e6eae4d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "What do you want to predict (your target variable)?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ad84a052a864283b405c41000cf1cbe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "What information do you want to use to predict the target variable?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf04f633eef44a63b05d9adec36d352c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='')"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xN9ELJEN7CZz",
        "colab_type": "code",
        "outputId": "8f5d7135-ca1d-46a7-8fa6-dfb5259acad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#type_of_dataset = text.value\n",
        "type_of_dataset = input(\"What is the topic of the business problem would you like to solve? For example, try 'Boston Education Data'\\n\")\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "  \n",
        "word_tokens = word_tokenize(type_of_dataset) \n",
        "  \n",
        "filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "  \n",
        "filtered_sentence = [] \n",
        "  \n",
        "for w in word_tokens: \n",
        "    if w not in stop_words: \n",
        "        filtered_sentence.append(w) "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is the topic of the business problem would you like to solve? For example, try 'Boston Education Data'\n",
            "Boston Education Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wZi7SEbv7CZ3",
        "colab_type": "code",
        "outputId": "a453f724-2606-4659-db41-1d1dd1852ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(filtered_sentence)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Boston', 'Education', 'Data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eXFCH2jS7CZ6",
        "colab_type": "code",
        "outputId": "a79f05c2-229c-46ca-d095-f236bf9bb3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "#Unused code\n",
        "string = [x.strip() for x in variables.split(',')]\n",
        "predicted_variable = string[0]\n",
        "feature = string[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9cadad1ded3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "slUbDKcn7CZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Find and download the right dataset for you"
      ]
    },
    {
      "metadata": {
        "id": "O_11Hzgk7CZ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "URL = 'https://toolbox.google.com/datasetsearch/search?query=' + filtered_sentence[0] + '%20' + filtered_sentence[1] + '%20' + filtered_sentence[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gTC_KBq07CZ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = requests.get(URL) #gets all the content of webpage\n",
        "soup = BeautifulSoup(data.text,'html.parser')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "0exE2djL7CaB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hi = soup.prettify()\n",
        "hi = soup.get_text()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "g466xfbf7CaH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hi = str(hi)\n",
        "#unwanted = soup.find('div', {'class' : 'iKH1Bc'})\n",
        "hi = hi.split(\"data:function(){return \",1)[1]\n",
        "l = hi.replace('null','')\n",
        "p = l.replace('\\n', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "EMydyTwF7CaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "#Get Next Name of Dataset\n",
        "compare = []\n",
        "\n",
        "rest = p.split(\"'\\\\',\", 1)[0]\n",
        "#txtl = rest.split('\"https://www.')[1::2]\n",
        "#txt2 = str(txtl).split(',')[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SlnURC_s7CaM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#rest = re.findall('\"([^\"]*)\"', rest)\n",
        "\n",
        "rest = re.findall('\"([^\"]*)\"', rest)\n",
        "#print(rest[8])\n",
        "#compare.append(rest[8])\n",
        "#data_url = rest[2]\n",
        "#print(data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "xbWr4cNk7CaR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Code reused from https://stackoverflow.com/questions/28050350/split-list-of-strings-into-list-of-sublists-based-on-a-string\n",
        "questionchunks = []\n",
        "hithere = []\n",
        "qlist = []\n",
        "#rest.append('\\\\') # append an empty str at the end to avoid the other condn\n",
        "for line in rest:\n",
        "\n",
        "    if (line != '\\\\' ):\n",
        "        questionchunks.append(line)      # add the element to each of your chunk   \n",
        "    else: \n",
        "        qlist.append(questionchunks)   # append chunk\n",
        "        questionchunks = []       # reset chunk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "yIxNeN0w7CaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flat_list = [item for sublist in qlist for item in sublist]\n",
        "#import numpy\n",
        "#a = np.array(qlist)\n",
        "#b = a.flatten()\n",
        "#b\n",
        "#a = a.tolist()\n",
        "#a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "sP1kHCQw7CaZ",
        "colab_type": "code",
        "outputId": "72708a68-d77e-4a90-ed2f-a30030b3ac78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1317
        }
      },
      "cell_type": "code",
      "source": [
        "real_list=[]\n",
        "real_list.append([item.split() for item in ' '.join(flat_list).split('AAAAAA') if item])\n",
        "#real_list[0][1]\n",
        "c= 0\n",
        "for x in real_list:\n",
        "    for y in x:\n",
        "        c = c +1\n",
        "print(c)\n",
        "\n",
        "real_list[0][0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Boston',\n",
              " 'Education',\n",
              " 'Data',\n",
              " 'BOSTON',\n",
              " 'EDUCATION',\n",
              " 'SKILLS',\n",
              " '\\\\u0026',\n",
              " 'TRAINING',\n",
              " 'CORP,',\n",
              " 'fiscal',\n",
              " 'year',\n",
              " 'ending',\n",
              " 'June',\n",
              " '2016',\n",
              " 'https://projects.propublica.org/nonprofits/organizations/200917822',\n",
              " 'projects.propublica.org',\n",
              " 'propublica.org',\n",
              " 'ProPublica',\n",
              " 'https://www.propublica.org/',\n",
              " 'https://t3.gstatic.com/images?q\\\\u003dtbn:ANd9GcQ1dChJXB5pbJLxU2cnp_0VWla6p3oHF5Cms-6QRTtG4qjRYMoL',\n",
              " '\\\\u003cp',\n",
              " 'class\\\\u003d\\\\',\n",
              " \"\\\\u003eProPublica's\",\n",
              " 'Nonprofit',\n",
              " 'Explorer',\n",
              " 'lets',\n",
              " 'you',\n",
              " 'view',\n",
              " 'summaries',\n",
              " 'of',\n",
              " '2.2',\n",
              " 'million',\n",
              " 'tax',\n",
              " 'returns',\n",
              " 'from',\n",
              " 'tax-exempt',\n",
              " 'organizations',\n",
              " 'and',\n",
              " 'see',\n",
              " 'financial',\n",
              " 'details',\n",
              " 'such',\n",
              " 'as',\n",
              " 'their',\n",
              " 'executive',\n",
              " 'compensation',\n",
              " 'and',\n",
              " 'revenue',\n",
              " 'and',\n",
              " 'expenses.',\n",
              " 'You',\n",
              " 'can',\n",
              " 'browse',\n",
              " 'raw',\n",
              " 'IRS',\n",
              " 'data',\n",
              " 'released',\n",
              " 'since',\n",
              " '2013',\n",
              " 'and',\n",
              " 'access',\n",
              " 'over',\n",
              " '9.4',\n",
              " 'million',\n",
              " 'tax',\n",
              " 'filing',\n",
              " 'documents',\n",
              " 'going',\n",
              " 'back',\n",
              " 'as',\n",
              " 'far',\n",
              " 'as',\n",
              " '2001.\\\\u003c/p\\\\u003e',\n",
              " '4e2LlIyFc6zJo0rt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "qwoH60Gp7Cab",
        "colab_type": "code",
        "outputId": "66ae1a99-12c3-44ce-c6b1-44eef7a81197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "for pi in range(0,1):\n",
        "    result = (real_list[0][0])\n",
        "    #print(qlist[1], \"\\n\")\n",
        "    #result = (qlist[0][24:])\n",
        "    print(result, \"\\n\")\n",
        "    hello = []\n",
        "\n",
        "    preprocessed_text = re.sub(r'.*\\u003e', '\\u003e', str(result))\n",
        "    \n",
        "    hello.append(preprocessed_text)\n",
        "\n",
        "    hi = str(hello).replace(\"\\\\\", \"\")\n",
        "    bye = hi.replace(\"/br\", \" \")\n",
        "    bye.replace(\"/p\", \" \")\n",
        "    rep = {\"src\": \"\", \"alt\": \n",
        "           \"\", \"a href\": \"\", \"pnnp\": \"\", \"class\": \"\", \"/a\": \"\", \"/em\": \"\", \"/p\": \"\", \"img\": \"\", \n",
        "           \"boqResearchsciencesearchdesktopuiDetailDescriptionElement_\": \"\",  \"blockquote\": \"\", \"u003e\": \"\", \"u003d\" : \"\", \"u003c\": \"\", \"\\\\\": \"\"} \n",
        "\n",
        "    rep = dict((re.escape(k), v) for k, v in rep.items())\n",
        "    pattern = re.compile(\"|\".join(rep.keys()))\n",
        "    text = pattern.sub(lambda m: rep[re.escape(m.group(0))], bye)\n",
        "    best = re.sub('07pwN8NZpOr9gbTfAAAAAA', '', text) \n",
        "\n",
        "    print(best, \"\\n\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Boston', 'Education', 'Data', 'BOSTON', 'EDUCATION', 'SKILLS', '\\\\u0026', 'TRAINING', 'CORP,', 'fiscal', 'year', 'ending', 'June', '2016', 'https://projects.propublica.org/nonprofits/organizations/200917822', 'projects.propublica.org', 'propublica.org', 'ProPublica', 'https://www.propublica.org/', 'https://t3.gstatic.com/images?q\\\\u003dtbn:ANd9GcQ1dChJXB5pbJLxU2cnp_0VWla6p3oHF5Cms-6QRTtG4qjRYMoL', '\\\\u003cp', 'class\\\\u003d\\\\', \"\\\\u003eProPublica's\", 'Nonprofit', 'Explorer', 'lets', 'you', 'view', 'summaries', 'of', '2.2', 'million', 'tax', 'returns', 'from', 'tax-exempt', 'organizations', 'and', 'see', 'financial', 'details', 'such', 'as', 'their', 'executive', 'compensation', 'and', 'revenue', 'and', 'expenses.', 'You', 'can', 'browse', 'raw', 'IRS', 'data', 'released', 'since', '2013', 'and', 'access', 'over', '9.4', 'million', 'tax', 'filing', 'documents', 'going', 'back', 'as', 'far', 'as', '2001.\\\\u003c/p\\\\u003e', '4e2LlIyFc6zJo0rt'] \n",
            "\n",
            "['['Boston', 'Education', 'Data', 'BOSTON', 'EDUCATION', 'SKILLS', 'u0026', 'TRAINING', 'CORP,', 'fiscal', 'year', 'ending', 'June', '2016', 'https:/rojects.propublica.org/nonprofits/organizations/200917822', 'projects.propublica.org', 'propublica.org', 'ProPublica', 'https://www.propublica.org/', 'https://t3.gstatic.com/images?qtbn:ANd9GcQ1dChJXB5pbJLxU2cnp_0VWla6p3oHF5Cms-6QRTtG4qjRYMoL', 'p', '', \"ProPublica's\", 'Nonprofit', 'Explorer', 'lets', 'you', 'view', 'summaries', 'of', '2.2', 'million', 'tax', 'returns', 'from', 'tax-exempt', 'organizations', 'and', 'see', 'financial', 'details', 'such', 'as', 'their', 'executive', 'compensation', 'and', 'revenue', 'and', 'expenses.', 'You', 'can', 'browse', 'raw', 'IRS', 'data', 'released', 'since', '2013', 'and', 'access', 'over', '9.4', 'million', 'tax', 'filing', 'documents', 'going', 'back', 'as', 'far', 'as', '2001.', '4e2LlIyFc6zJo0rt']'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "lCAF48eT7Cad",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_list = str(text).replace('\" ' '\",', \"\")\n",
        "newer_list = str(new_list).replace('\\'', \"\")\n",
        "another_list = str(newer_list).replace(',', \"\")\n",
        "another_new_list = str(another_list).replace('\"', \"\")\n",
        "\n",
        "string = another_new_list.replace('[','').replace(']','')\n",
        "text = re.sub(r'@\\S+', 'Someone', string)\n",
        "text = text.replace(\"title\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "wuPGPp477Cag",
        "colab_type": "code",
        "outputId": "77887604-61bd-4093-f3cc-db07ec42e4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r\"\\d*([^\\d\\W]+)\\d*\")\n",
        "text = re.sub(r'http\\S+', '', text)\n",
        "text = pattern.sub(r\"\\1\", text)\n",
        "text = text.replace(\"  \", \" \")\n",
        "text = text.rsplit(' ', 1)[0]\n",
        "\n",
        "text"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Boston Education Data BOSTON EDUCATION SKILLS u TRAINING CORP fiscal year ending June 2016 projects.propublica.org propublica.org ProPublica  p ProPublicas Nonprofit Explorer lets you view summaries of 2.2 million tax returns from tax-exempt organizations and see financial details such as their executive compensation and revenue and expenses. You can browse raw IRS data released since 2013 and access over 9.4 million tax filing documents going back as far as 2001.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "GNnIE4Hu7Cah",
        "colab_type": "code",
        "outputId": "c05784c1-97d2-4b12-8fa1-ca402261a2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1213
        }
      },
      "cell_type": "code",
      "source": [
        "x = [str(i) for i in text.split()]\n",
        "x"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Boston',\n",
              " 'Education',\n",
              " 'Data',\n",
              " 'BOSTON',\n",
              " 'EDUCATION',\n",
              " 'SKILLS',\n",
              " 'u',\n",
              " 'TRAINING',\n",
              " 'CORP',\n",
              " 'fiscal',\n",
              " 'year',\n",
              " 'ending',\n",
              " 'June',\n",
              " '2016',\n",
              " 'projects.propublica.org',\n",
              " 'propublica.org',\n",
              " 'ProPublica',\n",
              " 'p',\n",
              " 'ProPublicas',\n",
              " 'Nonprofit',\n",
              " 'Explorer',\n",
              " 'lets',\n",
              " 'you',\n",
              " 'view',\n",
              " 'summaries',\n",
              " 'of',\n",
              " '2.2',\n",
              " 'million',\n",
              " 'tax',\n",
              " 'returns',\n",
              " 'from',\n",
              " 'tax-exempt',\n",
              " 'organizations',\n",
              " 'and',\n",
              " 'see',\n",
              " 'financial',\n",
              " 'details',\n",
              " 'such',\n",
              " 'as',\n",
              " 'their',\n",
              " 'executive',\n",
              " 'compensation',\n",
              " 'and',\n",
              " 'revenue',\n",
              " 'and',\n",
              " 'expenses.',\n",
              " 'You',\n",
              " 'can',\n",
              " 'browse',\n",
              " 'raw',\n",
              " 'IRS',\n",
              " 'data',\n",
              " 'released',\n",
              " 'since',\n",
              " '2013',\n",
              " 'and',\n",
              " 'access',\n",
              " 'over',\n",
              " '9.4',\n",
              " 'million',\n",
              " 'tax',\n",
              " 'filing',\n",
              " 'documents',\n",
              " 'going',\n",
              " 'back',\n",
              " 'as',\n",
              " 'far',\n",
              " 'as',\n",
              " '2001.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "APDTA_5Q7Cak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for word in x:\n",
        "    if word.endswith(\".txt\") == True:\n",
        "        text = text.replace(word, \" \")\n",
        "    if word.endswith(\".csv\") == True:\n",
        "        text = text.replace(word, \" \")\n",
        "    if word.endswith(\".py\") == True:\n",
        "        text = text.replace(word, \" \")\n",
        "    if word.endswith(\".com\") == True:\n",
        "        text = text.replace(word, \" \")\n",
        "    if word.endswith(\".org\") == True:\n",
        "        text = text.replace(word, \" \")\n",
        "    if word.endswith(\".edu\") == True:\n",
        "        text = text.replace(word, \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z6_arYu6dPSZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The final text parsed from one of the results returned by Google Data Search:  **"
      ]
    },
    {
      "metadata": {
        "id": "9Ya0ftSkdOV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "69efa41e-c760-4452-90d9-36fa27d20144"
      },
      "cell_type": "code",
      "source": [
        "text"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Boston Education Data BOSTON EDUCATION SKILLS u TRAINING CORP fiscal year ending June 2016     ProPublica  p ProPublicas Nonprofit Explorer lets you view summaries of 2.2 million tax returns from tax-exempt organizations and see financial details such as their executive compensation and revenue and expenses. You can browse raw IRS data released since 2013 and access over 9.4 million tax filing documents going back as far as 2001.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "_zVHRiurbJ3Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Fuzzy text string matching algorithm experiments**"
      ]
    },
    {
      "metadata": {
        "id": "P4DcBn0y7Can",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb08a1a5-7460-41bc-ce44-67cf3e69a3ef"
      },
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "fuzz.ratio(text, 'Data from boston public schools')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "Rtv-vig77Cao",
        "colab_type": "code",
        "outputId": "63e9853f-c946-43fb-8dd8-d91f719b018d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "fuzz.partial_ratio(text, 'Data from boston public schools')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "s-wKt6JL7Caq",
        "colab_type": "code",
        "outputId": "996da234-0933-487a-d571-82f73e7f0a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Best option, so far - resilient to false positives \n",
        "from fuzzywuzzy import fuzz\n",
        "fuzz.token_sort_ratio(text, 'Data from boston public schools')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "morr2lxM7Cau",
        "colab_type": "code",
        "outputId": "41ae0b93-b662-4962-e47b-9f35f12f6091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "fuzz.token_set_ratio(text, 'Data from boston public schools')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}